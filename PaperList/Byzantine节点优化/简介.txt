《Asynchronous Byzantine Machine Learning (the case of SGD)》
分布式异步SGD算法对抗恶意节点，Krum的合作者写的。

《Byzantine Stochastic Gradient Descent》
提出了一种算法（ByzantineSGD），并分析了它的运行效率和抵抗能力
恶意节点容忍度<1/2

《Byzantine-Tolerant Machine Learning》
（是《Machine Learning with Adversaries Byzantine Tolerant Gradient Descent》的完善版本）
提出Krum并说明线性聚合方式对于抵抗攻击是无效的
提出并应用(α, f)-Byzantine resilience，证明Krum的收敛性（聚合方式有基于聚合和基于多数，krum属于基于多数）
另外，证明了收敛的计算时间为O(n2 · (d + log n))，n是节点数量，d是特征维数

《Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent》
较早的一篇（2017），分析了几何中值做抵抗时的算法复杂度
证明（依概率）一致收敛，参数以一定的误差在O(logN)次迭代收敛
一个特点：节点极多，做中值操作之前还需要先mini-batch
恶意节点容忍度：2(1 + ε )q ≤ m 

《Federated Machine Learning: Concept and Applications》
杨强的联邦学习

《Generalized Byzantine-tolerant SGD》
基于(α, f)-Byzantine resilience的理论，证明了几何中值等三种中值方法的收敛性
另外也提到了计算开销的复杂度问题

《Machine Learning with Adversaries Byzantine Tolerant Gradient Descent》
（《Byzantine-Tolerant Machine Learning》的初期版本）
提出了Krum，并简述了(α，f)收敛性，更偏向于sketch，附有部分证明

《SGD: Decentralized Byzantine Resilience》
GUANYU：异步更新，容忍1/3的恶意节点
基于(α, f)-Byzantine resilient的Gradient Aggregation Rules (GARs)
提到了一些攻击方法，可以参考。另外作为写作指导也很不错

《Zeno: Byzantine-suspicious stochastic gradientdescent》
第一个证明了Byzantine节点数量多的时候也能收敛：majority-based algorithms可能会失败，suspicion-based algorithm能够解决这个问题
从限制方差的角度来证明
基于方法的证明，暂时不用看
注：
本文提出的算法基于一个假设：byzantine节点在攻击时不知道正常节点上传的梯度

《Resilient Distributed Optimization Algorithms for Resource Allocation》
提出基于resilient primal-dual的方法，将一种恢复均值点的聚合方法与primal-dual data resource allocation（PD-DRA）方法结合起来，依然是有中心的结构，Byzantine节点<1/2

《Adversary-resilient Inference and Machine Learning: From Distributed to Decentralized》
关于中心化和去中心化结构的Byzantine攻击和抵抗做了一个综述，可参考的文章较多

《Fall of Empires Breaking Byzantine-tolerant SGD by Inner Product Manipulation》
证明在inner production manipulation攻击下coordinate-wise median和Krum方法可能是不可靠的。
“基本想法是当接近最优解时，正常节点的平均随机梯度接近于0，那么即使median和krum能够保证聚合结果离正常节点的平均随机梯度很近，方向也有可能是相反的”
最后文章提出需要修改关于Byzantine Tolerance的定义（Definition 4. (DSSGD-Byzantine Tolerance)）


《The Hidden Vulnerability of Distributed Learning in Byzantium》
提出一种针对Krum和Geometric Median等基于范数的鲁棒聚合算法的攻击以及对应的防御算法Bulyan。
Krum和GeoMed抵抗攻击能力都强烈依赖于诚实节点之间梯度的一致性。当诚实节点间梯度不一致时，这种分歧会留给攻击者一定的操作空间。文章构造的这种攻击就是利用这种分歧掩盖这种攻击，并在所留下的操作空间里尝试控制最终的聚合结果，这种攻击对Krum和GeoMed破坏力极大。
文章提出Bulyan算法，可以看作Krum和GeoMed的堆叠版本。算法先计算通常的Krum和GeoMed，选出梯度集合里最靠近聚合结果的梯度，拿出来并记录，多次重复。对这些拿出来的梯度进行简单平均，就是聚合算法Bulyan。

《Mitigating Sybils in Federated Learning Poisoning》
女巫攻击的抵抗。在上面大部分Byzantine resilience文章中，恶意节点的数量不超过一定数量几乎是一项必然要求，但实际中，恶意用户可以试图创建多个属于自己的节点，轻而易举地攻破上面majority based的算法。这种攻击方式就叫女巫攻击。
研究女巫攻击的文章不多，这里补充一篇，文章提出了FoolsGold算法。然而这篇文章抵抗女巫攻击的立足点是在城市节点的Non-IID性质和女巫攻击节点的相似性上。诚实节点返回信息不相似，女巫节点之间非常相似，因而可以设法把他们分辨开来。
理论上这种方式和原来的要求恶意节点不能太多的要求并没有什么不同。对城市节点充分Non-IID的要求限制了算法可用性。该文仅供参考。

《Robust federated learning in a heterogeneous environment》
在数据是非iid的情况下（Heterogeneous），通过cluster解决联邦学习中的Byzantine攻击问题。
从统计意义上证明了Lloyds算法的可靠性（Lloyds与k-means有一些区别，但文中似乎没有区分）

《Local Model Poisoning Attacks to Byzantine-Robust Federated Learning》
1、这篇文章主要的想法是设计特定的攻击方式，使得现有鲁棒算法学到的模型往错误的方向走。思路与Cong Xie, Sanmi Koyejo, and Indranil Gupta. Fall of empires: Breaking byzantine-tolerant sgd by inner product manipulation这篇文章很接近。
2、作者区分了data poisoning attack与local model poisoning attack。个人觉得，在用基于SGD的算法时，这两种攻击差距不大。
3、这篇文章最大的问题是假设数据不是i.i.d.的。从图三可以看出来，大部分鲁棒算法（除了Krum）在i.i.d.情况下表现都不错，但non-i.i.d.情况下性能就下降很快。说明作者没有认真的研究现有鲁棒算法的基本假设。
4、这篇文章还设计了两种防御方法，基本思路是在中心节点引入额外的测试样本帮助识别可能的恶意攻击。本质上可以认为是一种利用redundant data抵抗攻击的方法，但复杂度比较高。

